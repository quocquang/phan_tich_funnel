import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import openpyxl
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.impute import SimpleImputer

# C·∫•u h√¨nh trang Streamlit
st.set_page_config(layout="wide", page_title="Ph√¢n T√≠ch Funnel")

# CSS t√πy ch·ªânh giao di·ªán
st.markdown("""
    <style>
    .main > div {
        padding: 2rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        height: 3rem;
    }
    </style>
""", unsafe_allow_html=True)

# ------------------- H√†m x·ª≠ l√Ω d·ªØ li·ªáu ------------------- #
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        elif file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file)
        else:
            st.error("ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Vui l√≤ng s·ª≠ d·ª•ng CSV ho·∫∑c Excel.")
            return None

        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a ·ªü t√™n c·ªôt
        df.columns = df.columns.str.strip()

        # Chuy·ªÉn ƒë·ªïi c√°c c·ªôt ng√†y th√°ng
        date_columns = ["Ng√†y d·ª± ki·∫øn k√≠ Hƒê", "Th·ªùi ƒëi·ªÉm t·∫°o"]
        for col in date_columns:
            df[col] = pd.to_datetime(df[col], format="%d/%m/%Y", errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file: {str(e)}")
        return None

# ------------------- H√†m l·ªçc d·ªØ li·ªáu ------------------- #

def apply_filters(df, filters):
    filtered_df = df.copy()
    
    if filters.get("T√™n kh√°ch h√†ng"):
        filtered_df = filtered_df[filtered_df["T√™n kh√°ch h√†ng"].isin(filters["T√™n kh√°ch h√†ng"])]
        
    if filters.get("Giai ƒëo·∫°n"):
        filtered_df = filtered_df[filtered_df["Giai ƒëo·∫°n"].isin(filters["Giai ƒëo·∫°n"])]
        
    if filters.get("T·ªâ l·ªá th·∫Øng"):
        filtered_df = filtered_df[filtered_df["T·ªâ l·ªá th·∫Øng"].isin(filters["T·ªâ l·ªá th·∫Øng"])]
        
    if filters.get("T·ªânh/TP"):
        filtered_df = filtered_df[filtered_df["T·ªânh/TP"].isin(filters["T·ªânh/TP"])]
    
    if filters.get("Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£"):
        filtered_df = filtered_df[
            filtered_df["Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£"].isin(
                filters["Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£"]
            )
        ]
        
    if filters.get("Ng√†nh h√†ng"):
        filtered_df = filtered_df[filtered_df["Ng√†nh h√†ng"].isin(filters["Ng√†nh h√†ng"])]
        
    return filtered_df

def show_filters(df):
    st.sidebar.header("B·ªô l·ªçc")
    
    # X·ª≠ l√Ω gi√° tr·ªã NaN n·∫øu c·∫ßn cho c√°c c·ªôt hi·ªÉn th·ªã
    if "T√™n kh√°ch h√†ng" in df.columns:
        df["T√™n kh√°ch h√†ng"].fillna("Unknown", inplace=True)
    if "Ng√†nh h√†ng" in df.columns:
        df["Ng√†nh h√†ng"].fillna("Unknown", inplace=True)
    
    filters = {
        "T√™n kh√°ch h√†ng": st.sidebar.multiselect("T√™n kh√°ch h√†ng:", options=sorted(df["T√™n kh√°ch h√†ng"].unique())),
        "Giai ƒëo·∫°n": st.sidebar.multiselect("Giai ƒëo·∫°n:", options=sorted(df["Giai ƒëo·∫°n"].unique())),
        "T·ªâ l·ªá th·∫Øng": st.sidebar.multiselect("T·ªâ l·ªá th·∫Øng:", options=sorted(df["T·ªâ l·ªá th·∫Øng"].unique())),
        "T·ªânh/TP": st.sidebar.multiselect("T·ªânh/TP:", options=sorted(df["T·ªânh/TP"].astype(str).unique())),
        "Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£": st.sidebar.multiselect("Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£:", options=sorted(df["Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£"].unique())),
        "Ng√†nh h√†ng": st.sidebar.multiselect("Ng√†nh h√†ng:", options=sorted(df["Ng√†nh h√†ng"].unique())),
    }
    
    return apply_filters(df, filters)

# ------------------- H√†m hi·ªÉn th·ªã trang b√¨a ------------------- #

def show_cover_page():
    st.title("Ph√¢n T√≠ch Funnel")
    st.write("""
        **M·ª•c ti√™u:** ·ª®ng d·ª•ng n√†y gi√∫p ph√¢n t√≠ch Funnel, theo d√µi hi·ªáu su·∫•t v√† x√°c ƒë·ªãnh c√°c kho·∫£n Funnel.
        **T√≠nh nƒÉng:**
        - L·ªçc d·ªØ li·ªáu theo th·ªùi gian, khu v·ª±c, tr·∫°ng th√°i, v√† ng∆∞·ªùi qu·∫£n l√Ω.
        - Tr√¨nh b√†y tr·ª±c quan c√°c ch·ªâ s·ªë ch√≠nh v√† bi·ªÉu ƒë·ªì ph√¢n t√≠ch chi ti·∫øt.
        - Xu·∫•t d·ªØ li·ªáu ƒë√£ l·ªçc d∆∞·ªõi d·∫°ng CSV/Excel.
    """)
    st.image("https://github.com/user-attachments/assets/f263bd14-23a4-4735-b082-1d10ade1bbb0", use_column_width=True)

# ------------------- H√†m main ------------------- #

# T√≠nh c√°c ch·ªâ s·ªë ph√¢n t√≠ch m√¥ t·∫£
def calculate_descriptive_metrics(df):
    metrics = {}
    
    # 1. T·ªïng s·ªë c∆° h·ªôi
    metrics['total_opportunities'] = len(df)
    
    # 2. Ph√¢n b·ªë c∆° h·ªôi theo Giai ƒëo·∫°n
    stage_dist = df['Giai ƒëo·∫°n'].value_counts(normalize=True) * 100
    metrics['stage_distribution'] = stage_dist
    
    # 3. T·ªïng doanh thu d·ª± ki·∫øn
    metrics['total_expected_revenue'] = df['Doanh thu d·ª± ki·∫øn'].sum()
    
    # 4. Doanh thu d·ª± ki·∫øn trung b√¨nh
    metrics['avg_expected_revenue'] = df['Doanh thu d·ª± ki·∫øn'].mean()
    
    # 5. Doanh thu d·ª± ki·∫øn trung v·ªã
    metrics['median_expected_revenue'] = df['Doanh thu d·ª± ki·∫øn'].median()
    
    # 6. ƒê·ªô l·ªách chu·∫©n c·ªßa doanh thu d·ª± ki·∫øn
    metrics['std_expected_revenue'] = df['Doanh thu d·ª± ki·∫øn'].std()
    
    # 7. Ph√¢n b·ªë doanh thu d·ª± ki·∫øn theo Giai ƒëo·∫°n
    revenue_by_stage = df.groupby('Giai ƒëo·∫°n')['Doanh thu d·ª± ki·∫øn'].describe()
    metrics['revenue_by_stage'] = revenue_by_stage
    
    # 8. T·ªâ l·ªá th·∫Øng trung b√¨nh
    df['T·ªâ l·ªá th·∫Øng'] = pd.to_numeric(df['T·ªâ l·ªá th·∫Øng'], errors='coerce')
    metrics['avg_win_rate'] = df['T·ªâ l·ªá th·∫Øng'].mean()
    
    # 9. Ph√¢n b·ªë t·ªâ l·ªá th·∫Øng theo Nh√¢n vi√™n kinh doanh
    win_rate_by_salesperson = df.groupby('Nh√¢n vi√™n kinh doanh')['T·ªâ l·ªá th·∫Øng'].mean()
    metrics['win_rate_by_salesperson'] = win_rate_by_salesperson
    
    # 10. Ph√¢n b·ªë c∆° h·ªôi theo Tr·∫°ng th√°i
    status_dist = df['Tr·∫°ng th√°i'].value_counts(normalize=True) * 100
    metrics['status_distribution'] = status_dist
    
    # 11. Ph√¢n b·ªë c∆° h·ªôi theo T·ªânh/TP
    location_dist = df['T·ªânh/TP'].value_counts(normalize=True) * 100
    metrics['location_distribution'] = location_dist
    
    # 12. Danh s√°ch kh√°ch h√†ng ch·ªß ch·ªët v√† s·ªë l∆∞·ª£ng c∆° h·ªôi
    top_customers = df['T√™n kh√°ch h√†ng'].value_counts().head(10)
    metrics['top_customers'] = top_customers
    
    # 13. Ph√¢n b·ªë c∆° h·ªôi theo Nh√≥m kh√°ch h√†ng (ch√≠nh s√°ch c√¥ng n·ª£)
    customer_group_dist = df['Nh√≥m kh√°ch h√†ng theo ch√≠nh s√°ch c√¥ng n·ª£'].value_counts(normalize=True) * 100
    metrics['customer_group_distribution'] = customer_group_dist
    
    # 14. T·ª∑ l·ªá chuy·ªÉn ƒë·ªïi c∆° h·ªôi (Conversion Rate)
    conversion_rate = (df['Giai ƒëo·∫°n'] == '90% - Th·ª±c hi·ªán h·ª£p ƒë·ªìng').mean() * 100
    metrics['conversion_rate'] = conversion_rate
    
    # 15. Ph√¢n b·ªë theo Ngu·ªìn v·ªën
    funding_source_dist = df['Ngu·ªìn v·ªën'].value_counts(normalize=True) * 100
    metrics['funding_source_distribution'] = funding_source_dist
    
    # 16. Th·ªùi gian trung b√¨nh t·ª´ t·∫°o ƒë·∫øn k√Ω h·ª£p ƒë·ªìng
    df['time_to_sign'] = (df['Ng√†y d·ª± ki·∫øn k√≠ Hƒê'] - df['Th·ªùi ƒëi·ªÉm t·∫°o']).dt.days
    metrics['avg_time_to_sign'] = df['time_to_sign'].mean()
    
    # 17. Ph√¢n b·ªë c∆° h·ªôi theo ƒê·ªôi ng≈© b√°n h√†ng
    sales_team_dist = df['ƒê·ªôi ng≈© b√°n h√†ng'].value_counts(normalize=True) * 100
    metrics['sales_team_distribution'] = sales_team_dist
    
    # 18. T·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa c√°c ƒê·ªëi th·ªß c·∫°nh tranh
    competitor_freq = df['ƒê·ªëi th·ªß'].value_counts().head(10)
    metrics['competitor_frequency'] = competitor_freq
    
    # 19. S·ªë l∆∞·ª£ng c∆° h·ªôi theo H√£ng s·∫£n xu·∫•t
    manufacturer_dist = df['H√£ng s·∫£n xu·∫•t'].value_counts(normalize=True) * 100
    metrics['manufacturer_distribution'] = manufacturer_dist
    
    # 20. Ph√¢n b·ªë theo H·ªá s·ªë quy ƒë·ªïi ti·ªÅn t·ªá
    currency_conversion_dist = df['H·ªá s·ªë quy ƒë·ªïi ti·ªÅn t·ªá'].value_counts(normalize=True) * 100
    metrics['currency_conversion_distribution'] = currency_conversion_dist
    
    # 21. T·ªâ l·ªá c∆° h·ªôi m·ªõi vs c∆° h·ªôi c≈©
    new_vs_old_opportunities = df['Th·ªùi ƒëi·ªÉm t·∫°o'].value_counts(normalize=True) * 100
    metrics['new_vs_old_opportunities'] = new_vs_old_opportunities
    
    # 22. T·∫ßn su·∫•t c·∫≠p nh·∫≠t th√¥ng tin
    df['C·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o'] = pd.to_datetime(df['C·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o'], errors='coerce')
    update_freq = (df['C·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o'].max() - df['C·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o']).dt.days.mean()
    metrics['update_frequency'] = update_freq
    
    return metrics

# T√≠nh c√°c ch·ªâ s·ªë ph√¢n t√≠ch d·ª± ƒëo√°n
def calculate_predictive_metrics(df):
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh
    df_model = df.copy()
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
    if df_model.empty:
        raise ValueError("Dataframe r·ªóng, kh√¥ng th·ªÉ th·ª±c hi·ªán ph√¢n t√≠ch d·ª± ƒëo√°n")
        
    # C√°c c·ªôt b·∫Øt bu·ªôc
    required_cols = ['Giai ƒëo·∫°n', 'Tr·∫°ng th√°i', 'Ng√†nh h√†ng', 
                     'Nh√¢n vi√™n kinh doanh', 'Doanh thu d·ª± ki·∫øn', 
                     'T·ªâ l·ªá th·∫Øng', 'Ng√†y d·ª± ki·∫øn k√≠ Hƒê', 'Th·ªùi ƒëi·ªÉm t·∫°o']
    missing_cols = [col for col in required_cols if col not in df_model.columns]
    if missing_cols:
        raise KeyError(f"Thi·∫øu c√°c c·ªôt quan tr·ªçng: {', '.join(missing_cols)}")
    
    # T√≠nh to√°n time_to_sign n·∫øu ch∆∞a c√≥
    if "time_to_sign" not in df_model.columns:
        df_model["time_to_sign"] = (df_model["Ng√†y d·ª± ki·∫øn k√≠ Hƒê"] - df_model["Th·ªùi ƒëi·ªÉm t·∫°o"]).dt.days
    
    # Lo·∫°i b·ªè nh·ªØng d√≤ng c√≥ time_to_sign kh√¥ng h·ª£p l·ªá (v√≠ d·ª•: <= 0)
    df_model = df_model[df_model["time_to_sign"] > 0]
    
    # Chuy·ªÉn ƒë·ªïi c√°c c·ªôt s·ªë v·ªÅ ki·ªÉu numeric
    df_model['Doanh thu d·ª± ki·∫øn'] = pd.to_numeric(df_model['Doanh thu d·ª± ki·∫øn'], errors='coerce')
    
    # X·ª≠ l√Ω c·ªôt "T·ªâ l·ªá th·∫Øng"
    if df_model['T·ªâ l·ªá th·∫Øng'].dtype == object:
        df_model['T·ªâ l·ªá th·∫Øng'] = pd.to_numeric(df_model['T·ªâ l·ªá th·∫Øng'].str.replace('%', ''), errors='coerce')
    else:
        df_model['T·ªâ l·ªá th·∫Øng'] = pd.to_numeric(df_model['T·ªâ l·ªá th·∫Øng'], errors='coerce')
    
    # M√£ h√≥a c√°c bi·∫øn categorical
    categorical_cols = ['Giai ƒëo·∫°n', 'Tr·∫°ng th√°i', 'Ng√†nh h√†ng', 'Nh√¢n vi√™n kinh doanh']
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    for col in categorical_cols:
        df_model[col] = le.fit_transform(df_model[col].astype(str))
    
    # Chu·∫©n b·ªã t·∫≠p t√≠nh nƒÉng v√† m·ª•c ti√™u
    X = df_model[categorical_cols + ['Doanh thu d·ª± ki·∫øn', 'T·ªâ l·ªá th·∫Øng']]
    y = df_model['time_to_sign'].values  # √©p y th√†nh m·∫£ng NumPy
    
    # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu b·∫±ng SimpleImputer
    from sklearn.impute import SimpleImputer
    imputer = SimpleImputer(strategy='mean')
    X = imputer.fit_transform(X)
    
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc c·ªßa X v√† y
    if X.shape[0] != y.shape[0]:
        raise ValueError(f"K√≠ch th∆∞·ªõc kh√¥ng kh·ªõp: X c√≥ {X.shape[0]} m·∫´u, y c√≥ {y.shape[0]} m·∫´u")
    
    # Hu·∫•n luy·ªán m√¥ h√¨nh RandomForestRegressor ƒë·ªÉ t√≠nh feature importance
    from sklearn.ensemble import RandomForestRegressor
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X, y)
    
    feature_importance = pd.DataFrame({
        'feature': categorical_cols + ['Doanh thu d·ª± ki·∫øn', 'T·ªâ l·ªá th·∫Øng'],
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # C√°c b∆∞·ªõc d·ª± ƒëo√°n kh√°c (v√≠ d·ª•: Logistic Regression, KMeans, vv.)
    # ...
    
    # D·ª± b√°o xu h∆∞·ªõng doanh thu theo th·ªùi gian
    df_model['Th·ªùi ƒëi·ªÉm t·∫°o'] = pd.to_datetime(df_model['Th·ªùi ƒëi·ªÉm t·∫°o'], errors='coerce')
    time_series_data = df_model.set_index('Th·ªùi ƒëi·ªÉm t·∫°o').resample('M')['Doanh thu d·ª± ki·∫øn'].sum()
    
    return feature_importance, df_model, time_series_data



# T√≠nh c√°c ch·ªâ s·ªë ph√¢n t√≠ch chu·∫©n ƒëo√°n
def calculate_diagnostic_metrics(df):
    # Ma tr·∫≠n t∆∞∆°ng quan
    numeric_cols = ['Doanh thu d·ª± ki·∫øn', 'T·ªâ l·ªá th·∫Øng', 'time_to_sign']
    corr_matrix = df[numeric_cols].corr()
    
    # Ph√¢n t√≠ch hi·ªáu su·∫•t nh√¢n vi√™n
    sales_performance = df.groupby('Nh√¢n vi√™n kinh doanh').agg({
        'Doanh thu d·ª± ki·∫øn': ['count', 'mean', 'sum'],
        'T·ªâ l·ªá th·∫Øng': 'mean'
    }).round(2)
    
    return corr_matrix, sales_performance

# H√†m main ch√≠nh
def main():
    st.title('üéØ H·ªá Th·ªëng Ph√¢n T√≠ch Funnel N√¢ng Cao')
    
    # Hi·ªÉn th·ªã trang b√¨a
    show_cover_page()
    
    # T·∫£i file d·ªØ li·ªáu t·ª´ sidebar
    uploaded_file = st.sidebar.file_uploader("üìÇ T·∫£i l√™n file d·ªØ li·ªáu", 
                                               type=['csv', 'xlsx', 'xls'],
                                               help="H·ªó tr·ª£ ƒë·ªãnh d·∫°ng CSV v√† Excel")
    
    if uploaded_file is not None:
        df = load_data(uploaded_file)
        
        if df is not None:
            # √Åp d·ª•ng b·ªô l·ªçc d·ªØ li·ªáu
            filtered_df = show_filters(df)
            
            # ƒê·∫£m b·∫£o c√°c c·ªôt t√†i ch√≠nh l√† s·ªë
            filtered_df['Doanh thu d·ª± ki·∫øn'] = pd.to_numeric(filtered_df['Doanh thu d·ª± ki·∫øn'], errors='coerce').fillna(0)
            
            # T√≠nh to√°n c√°c ch·ªâ s·ªë
            desc_metrics = calculate_descriptive_metrics(filtered_df)
            feature_importance, df_with_predictions, time_series_data = calculate_predictive_metrics(filtered_df)
            if feature_importance is None or df_with_predictions is None or time_series_data is None:
                return
            corr_matrix, sales_performance = calculate_diagnostic_metrics(filtered_df)

            # Hi·ªÉn th·ªã dashboard
            st.header("1. Ch·ªâ s·ªë Ph√¢n t√≠ch M√¥ t·∫£")

            # Metrics trong 3 c·ªôt
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("T·ªïng s·ªë c∆° h·ªôi", f"{desc_metrics['total_opportunities']:,}")
            with col2:
                st.metric("T·ªïng doanh thu d·ª± ki·∫øn", f"{desc_metrics['total_expected_revenue']:,.0f} VND")
            with col3:
                st.metric("T·ªâ l·ªá th·∫Øng trung b√¨nh", f"{desc_metrics['avg_win_rate']:.1f}%")

            # Th√™m c√°c metrics kh√°c
            col4, col5, col6 = st.columns(3)
            with col4:
                st.metric("Doanh thu trung b√¨nh", f"{desc_metrics['avg_expected_revenue']:,.0f} VND")
            with col5:
                st.metric("Doanh thu trung v·ªã", f"{desc_metrics['median_expected_revenue']:,.0f} VND")
            with col6:
                st.metric("Th·ªùi gian trung b√¨nh ƒë·∫øn k√Ω Hƒê", f"{desc_metrics['avg_time_to_sign']:.1f} ng√†y")

            # Bi·ªÉu ƒë·ªì ph√¢n t√≠ch
            st.subheader("Ph√¢n b·ªë doanh thu theo giai ƒëo·∫°n")
            fig1 = px.box(filtered_df, x="Giai ƒëo·∫°n", y="Doanh thu d·ª± ki·∫øn",
                          title="Ph√¢n b·ªë doanh thu d·ª± ki·∫øn theo giai ƒëo·∫°n")
            st.plotly_chart(fig1, use_container_width=True)

            # Ph√¢n t√≠ch d·ª± ƒëo√°n
            st.header("2. Ch·ªâ s·ªë Ph√¢n t√≠ch D·ª± ƒëo√°n")

            # Feature importance
            st.subheader("T·∫ßm quan tr·ªçng c·ªßa c√°c y·∫øu t·ªë")
            fig2 = px.bar(feature_importance, x='importance', y='feature', orientation='h',
                          title="Feature Importance trong d·ª± ƒëo√°n th·ªùi gian k√Ω h·ª£p ƒë·ªìng")
            st.plotly_chart(fig2, use_container_width=True)

            # D·ª± ƒëo√°n kh·∫£ nƒÉng th√†nh c√¥ng c·ªßa c∆° h·ªôi
            st.subheader("D·ª± ƒëo√°n kh·∫£ nƒÉng th√†nh c√¥ng c·ªßa c∆° h·ªôi")
            st.dataframe(df_with_predictions[['T√™n c∆° h·ªôi', 'success_prob']])

            # D·ª± ƒëo√°n doanh thu th·ª±c t·∫ø
            st.subheader("D·ª± ƒëo√°n doanh thu th·ª±c t·∫ø")
            st.dataframe(df_with_predictions[['T√™n c∆° h·ªôi', 'predicted_revenue']])

            # Ph√¢n lo·∫°i c∆° h·ªôi theo m·ª©c ƒë·ªô r·ªßi ro
            st.subheader("Ph√¢n lo·∫°i c∆° h·ªôi theo m·ª©c ƒë·ªô r·ªßi ro")
            st.dataframe(df_with_predictions[['T√™n c∆° h·ªôi', 'risk_level']])

            # D·ª± b√°o xu h∆∞·ªõng doanh thu theo th·ªùi gian
            st.subheader("D·ª± b√°o xu h∆∞·ªõng doanh thu theo th·ªùi gian")
            fig3 = px.line(time_series_data, title="D·ª± b√°o xu h∆∞·ªõng doanh thu theo th·ªùi gian")
            st.plotly_chart(fig3, use_container_width=True)

            # Ph√¢n t√≠ch chu·∫©n ƒëo√°n
            st.header("3. Ch·ªâ s·ªë Ph√¢n t√≠ch Chu·∫©n ƒëo√°n")

            # Ma tr·∫≠n t∆∞∆°ng quan
            st.subheader("Ma tr·∫≠n t∆∞∆°ng quan")
            fig4 = px.imshow(corr_matrix, 
                             labels=dict(color="Correlation"),
                             title="Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn s·ªë")
            st.plotly_chart(fig4, use_container_width=True)

            # Hi·ªáu su·∫•t nh√¢n vi√™n
            st.subheader("Ph√¢n t√≠ch hi·ªáu su·∫•t nh√¢n vi√™n kinh doanh")
            st.dataframe(sales_performance)

            # Th√™m t√≠nh nƒÉng ph√¢n t√≠ch theo th·ªùi gian
            st.header("4. Ph√¢n t√≠ch theo th·ªùi gian")

            # Timeline c·ªßa c√°c c∆° h·ªôi
            fig5 = px.timeline(
                filtered_df,
                x_start="Th·ªùi ƒëi·ªÉm t·∫°o",
                x_end="Ng√†y d·ª± ki·∫øn k√≠ Hƒê",
                y="T√™n c∆° h·ªôi",
                title="Timeline c√°c c∆° h·ªôi"
            )
            st.plotly_chart(fig5, use_container_width=True)

            # D·ªØ li·ªáu chi ti·∫øt
            st.header("5. D·ªØ li·ªáu chi ti·∫øt")
            st.dataframe(
                filtered_df.style.format({
                    "Doanh thu d·ª± ki·∫øn": "{:,.0f}",
                    "T·ªâ l·ªá th·∫Øng": "{:.1f}%"
                })
            )

            # Download button
            csv = filtered_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "T·∫£i d·ªØ li·ªáu",
                csv,
                "data.csv",
                "text/csv",
               key='download-csv'
            )
            
        else:
            st.info("Vui l√≤ng t·∫£i l√™n file d·ªØ li·ªáu ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n file d·ªØ li·ªáu ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")

if __name__ == '__main__':
    main()
